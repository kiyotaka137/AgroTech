# AgroTech

0. Запуск
Из корня дериктории python -m desktop.run. Самый первый запуск будет долгим из за скачивания модели

1. Постановка задачи
* Цель: по PDF-файлу с таблицами по рациону коров, химического анализа рациона и другими, предсказать процент различных кислот из списка в конечном продукте.
* Тип задачи: регрессия с рекомендательной системой

2. Данные
* Данные: около 100 сэмплов, собранных из PDF-отчётов по рациону и химическому анализу. Каждый отчёт содержит несколько таблиц, но из тех, которые есть во всех - только рацион и химический анализ

3. Наш подход 
* Разбор данных и формулировка целевой метрики. Провели разведку датасета, выделили целевую переменную. Задача регрессии, значит будет использовать для обучения MSELoss, а метрику RMSE, чтобы величины были такого же порядка и R^2 - чтобы понимать обобщающую способность модели
* Парсинг. Спарсили pdf-файл в pandas.DataFrame для дальнейшей работы, использовали 2 таблицы - рацион и хим анализ, так как они есть во всех отчетах
* Фиче-инжиниринг:
    * Сделали кастомный OHE для категориальных признаков
    * Сделали обработку None
    * Выкинули неифнормативные признаки
* Базовая модель: Для начала выбрали Ridge для baseline и смотрели на RMSE и R^2 на LOOCV
* Валидация: LOOCV - так как данный мало, порядка 100, а данный способ дает лучшие результаты
* Выбор моделей:  выбор пал на ансамбль из CatBoost, RandomForst, Ridge, SVR  + нормализация данных и подбор гиперпараметров на GridSearchCV
* Обработка названий рациона: регулярные выражения + mini-llm Qwen-3 0.6B
* Интерпретируемость: SHAP
* Результат: Из-за того что данных мало, то на тестовую выборку осталось 10 сэмплов, что не дает стабильные метрики для обучения (поэтому не привожу результатов)


3. Технические детали
* ML Использовали библиотеку scikit-learn для обучения модели, валидации и тп и SHAP для интерпретации
* Десктоп Использовали библиотек PyQt6 для создания десктоп приложения


4. Проблемы, с которыми столкнулись
* Очень малое количество данных, на которых более информативные модели нельзя обучить
* Ужасное качество и формат данных, которые по позволяют унифицировать в полной мере работу с ними


5. Что сработало лучше всего
* Модель Использовали ансамбль из CatBoost, RandomForest, Ridge, SVR + нормализация данных
* Ансамбль Для того чтобы в ансамбле модели были с каким-то весов, чтобы уравновешивать их, использовали 1/RMSE + normalization, RMSE брали усредненный по 10 запускам на LOOCV
* Почему ансамбль: отдельные модели показывают большой variance, а при ансамбле без потери bias мы можем уменьшать variance, что дает более стабильную и точную модель и меньший риск переобучения
* Гиперпараметры Подбирались с помощью GridSearchCV с кросс-валидацией (k‎ = 5) для всего ансамбля, сначала широкий поиск, далее более узкий
* Рекомендации Использовали SHAP для того, чтобы интерпретировать вклад признаков. Сделали SHAP для вклада признаков в предсказание кислоты, и вклада рациона в его химический анализ.


6. Интерпретация результатов
* Дана таблица с предсказанными значениями кислот
* В итоговом отчете есть графики SHAP, показывающие вклад каждого признака, то есть например если признак 1 дает увеличение сильное целевой переменной, то при уменьшении его, целевая переменная тоже уменьшиться, но стоит учитывать то, что из-за нелинейности ансамбля нет линейного уменьшения.
* Для удобства для кислот, а также для нутриентов приведены таблицы с топ самых влияющих признаков


7. Что можно улучшить
* При добавлении более качественных данных и большего по количеству обучить
* Более точный подбор гиперпараметров


8. Ограничения
* Модель обучена на малой выборке (~100 образцов), поэтому чувствительна к шуму.
* Из-за неунифицированных названий рационов возможны ошибки на этапе парсинга.
* Невозможно гарантировать переносимость результатов на другие фермы без адаптации под их данные.


9. Сервер централизации данных

   Эта функциональность позволяет создать единую точку сбора для всех данных о рационах и отчётах.
Как это работает:

*   Хранилище: Все записи пользователей (рационы и отчёты) сохраняются на удалённом сервере.
*   Доступ по ключу: Для подключения к серверу и просмотра данных используется  ключ (пароль).
*   Режим просмотра: В основном интерфейсе есть кнопка, при нажатии которой открывается отдельное окно. После ввода пароля в нём можно просматривать все записи всех пользователей. Редактирование в этом режиме недоступно.
*   Синхронизация: При закрытии приложения локальные данные обычного пользователя автоматически отправляются на сервер.

* Запуск сервера

```bash
git checkout centralization
cd centralization
docker compose up --build
